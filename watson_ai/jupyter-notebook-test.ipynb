{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://jp-tok.ml.cloud.ibm.com/ml/v1/text/generation?version=2023-05-29\"\n",
    "\n",
    "body = {\n",
    "\t\"input\": \"\"\"Please provide top 5 bullet points in the review provided in '\\'''\\'''\\''.\n",
    "\n",
    "\n",
    "Review:\n",
    "'\\'''\\'''\\''I had 2 problems with my experience with my refinance. 1) The appraisal company used only tried to lower my house value to fit the comps that he was able to find in the area. My house is unique and he did not use the unique pictures to compare value. He purposely left them out of the appraisal. 2) I started my loan process on a Thursday. On Saturday I tried to contact my loan officer to tell him of the American Express offer that I wanted to apply for. I was informed that it was too late and I could not use it because it would delay the process. I had just received the email about the offer and I had just started the process so how was it too late to get in on the $2,000 credit on my current bill. I let it go but I should have dropped the process and restarted it because that would have helped me out with my bill.'\\'''\\'''\\''\n",
    "\n",
    "Top bullet points:\n",
    "1. The appraisal company undervalued the reviewer'\\''s house by purposely excluding unique pictures that would have accurately assessed its value.\n",
    "2. The uniqueness of the house was not taken into consideration, and the appraiser relied solely on comps that did not reflect its true worth.\n",
    "3. The reviewer attempted to inform their loan officer about an American Express offer they wanted to apply for, which would have provided a $2,000 credit on their current bill.\n",
    "4. The loan officer stated it was too late to take advantage of the offer as it would delay the process, despite the reviewer having just received the email and recently started the loan process.\n",
    "5. The reviewer regrets not dropping the process and restarting it to benefit from the offer, as it would have helped them with their bill.\n",
    "\n",
    "\n",
    "Review:'\\'''\\'''\\''\n",
    "For the most part my experience was very quick and very easy. I did however, have 3 issues.\n",
    "\n",
    "#1 - When I received my final numbers, my costs were over $2000 more than was quoted to me over the phone. This was straightened out quickly and matched what I was quoted.\n",
    "\n",
    "#2 - The appraiser had to change his schedule and when I didn'\\''t know if I could be home for the appraisal, he said he could do it with me not there. I do not think this is a wise thing to do or to offer.\n",
    "\n",
    "#3 - When I received my appraisal, it was far lower than it should have been. My house appraised for basically the same price I purchased it for 14 years ago. I have kept the home up with flooring, paint, etc. It has new shingles on it from last summer, the driveway has been paved, I have about three acres landscaped compared to maybe one when I bought it, and have paved the driveway which was originally gravel.\n",
    "\n",
    "Even if you discount the insanely high prices that houses are selling for in today'\\''s market, the house has increased in value over the past fourteen years. In fact, some of the compared properties looked like camps that were not on water, had no basement or possibly no slab, and very minimal acreage. These comparably priced houses were in no way equal to my 4 bedroom cape, with a wraparound deck, on 4 acres, though not on the water, it is overlooking lake around 100 feet away at the most. I feel very strongly that the appraisal price was put in at a high enough estimate to satisfy the needs of the refinance loan.'\\'''\\'''\\''\n",
    "\n",
    "Top bullet points:\n",
    "1. Overall, the experience was quick and easy, but there were three specific issues.\n",
    "2. Initially, the quoted costs over the phone did not match the final numbers, resulting in a discrepancy of over $2000. However, this was promptly resolved.\n",
    "3. The appraiser offered to conduct the appraisal without the homeowner present, which the reviewer felt was unwise and not recommended.\n",
    "4. The appraisal value of the house was significantly lower than expected, even considering the current high housing market prices. The reviewer mentioned various upgrades and improvements made to the house over the past 14 years.\n",
    "5. The reviewer expressed a strong belief that the appraisal was deliberately set at a lower value to meet the requirements of the refinance loan, despite the property'\\''s unique features and advantages compared to the comparables used.\n",
    "\n",
    "\n",
    "Review:'\\'''\\'''\\''\n",
    "I was told upfront and throughout most of the process that I would be able to get a $25K payout/cash back based on the market value of my house that was discussed in the original conversation with the loan officer. However, midway into the process I was told by the loan officer that I was only able to get $17.5K back. Additionally, I was told that I would be able to skip 2 months of mortgage payment to help makeup for the cash shortage. However, at the end of the day I was told that I could only skip 1 mortgage payment. These 2 drawbacks caused me to not fully satisfy the financial reason of why I originally wanted to refinance which was to get the $25K cash.\n",
    "\n",
    "Top bullet points:\n",
    "1. The initial agreement with the loan officer stated that the reviewer would receive a $25K cash payout based on the market value of their house.\n",
    "2. Midway through the process, the loan officer informed the reviewer that they would only be eligible for a $17.5K cash payout, which was lower than initially discussed.\n",
    "3. The reviewer was also promised the ability to skip two months of mortgage payments to compensate for the cash shortage, but they were later informed that they could only skip one payment.\n",
    "4. These discrepancies in the cash payout amount and the reduced mortgage payment relief prevented the reviewer from fulfilling their original financial objective of obtaining the $25K cash.\n",
    "5. The limitations and changes in the terms impacted the overall satisfaction with the refinancing process and compromised the financial benefits the reviewer had anticipated.\n",
    "\n",
    "Review:'\\'''\\'''\\''\n",
    "I started my loan process toward securing a VA loan. I was waiting for a a month and a couple weeks, then I was told that the VA needed to acquire my retirement points to verify my veteran status. If I knew this is what my loan was on hold for, I could have contacted the VA office right away and got this cleared up. \n",
    "For whatever reason, it took the underwriting department a long time to verify my employment status, even after I uploaded a couple years of my W2 forms from both of my jobs, and they had my Social Security number to further verify my employment status. My loan completion date was extended, because I wasn'\\''t made aware that they were waiting for my VA status to be approved. The push back for my mortgage is common for mortgage companies, but this caused my interest rate to go up. Then, the securing of a closing lawyer being made aware to me and the lawyer needing three days to get their end prepared for me to go to their office to sign the paperwork wasn'\\''t made aware to me. My loan missed the second closing date. For whatever reason, the locked in interest rate jumped up 5/8 points. After making the banker I was working with aware of this, he didn'\\''t understand why the locked in interest rate jumped up either. He was nice enough to work on it and was able to get the interest rate down in 1/4 of a point, so my mortgage has an interest rate that is 3/8 of a point higher than my locked in interest rate in the beginning of this process. Although my interest rate is higher than the locked in interest point, at the end, the mortgage is successfully finished.\n",
    "'\\'''\\'''\\''\n",
    "\n",
    "Top bullet points:\n",
    "\"\"\",\n",
    "\t\"parameters\": {\n",
    "\t\t\"decoding_method\": \"greedy\",\n",
    "\t\t\"max_new_tokens\": 200,\n",
    "\t\t\"repetition_penalty\": 1\n",
    "\t},\n",
    "\t\"model_id\": \"google/flan-ul2\",\n",
    "\t\"project_id\": \"e6272693-3683-4971-bc24-5cf71802ca71\"\n",
    "}\n",
    "\n",
    "headers = {\n",
    "\t\"Accept\": \"application/json\",\n",
    "\t\"Content-Type\": \"application/json\",\n",
    "\t\"Authorization\": \"Bearer eyJraWQiOiIyMDI0MDUwNTA4MzkiLCJhbGciOiJSUzI1NiJ9.eyJpYW1faWQiOiJJQk1pZC02OTIwMDBDNjc2IiwiaWQiOiJJQk1pZC02OTIwMDBDNjc2IiwicmVhbG1pZCI6IklCTWlkIiwianRpIjoiMjdkMDlkZjQtN2FhYS00YTgwLWE1YjMtM2U0ZDI1NjZmOWU5IiwiaWRlbnRpZmllciI6IjY5MjAwMEM2NzYiLCJnaXZlbl9uYW1lIjoiQWxpIiwiZmFtaWx5X25hbWUiOiJNdXJ0YWRobyIsIm5hbWUiOiJBbGkgTXVydGFkaG8iLCJlbWFpbCI6ImlkLmFsaW11cnRhZGhvQGdtYWlsLmNvbSIsInN1YiI6ImlkLmFsaW11cnRhZGhvQGdtYWlsLmNvbSIsImF1dGhuIjp7InN1YiI6ImlkLmFsaW11cnRhZGhvQGdtYWlsLmNvbSIsImlhbV9pZCI6IklCTWlkLTY5MjAwMEM2NzYiLCJuYW1lIjoiQWxpIE11cnRhZGhvIiwiZ2l2ZW5fbmFtZSI6IkFsaSIsImZhbWlseV9uYW1lIjoiTXVydGFkaG8iLCJlbWFpbCI6ImlkLmFsaW11cnRhZGhvQGdtYWlsLmNvbSJ9LCJhY2NvdW50Ijp7InZhbGlkIjp0cnVlLCJic3MiOiIzOTlhMGRlNmEyNzE0ZTY3YTUwM2Y2N2Q0MzUwNmM1MSIsImltc191c2VyX2lkIjoiMTIwNTUzNzciLCJmcm96ZW4iOnRydWUsImlzX2VudGVycHJpc2VfYWNjb3VudCI6ZmFsc2UsImVudGVycHJpc2VfaWQiOiI5YTBjMjUwOWE0OTk0N2U0YTFkYjJhYzczZGI4MzI5MyIsImltcyI6IjI4MTEzNjkifSwiaWF0IjoxNzE1OTU0MDI4LCJleHAiOjE3MTU5NTc2MjgsImlzcyI6Imh0dHBzOi8vaWFtLmNsb3VkLmlibS5jb20vaWRlbnRpdHkiLCJncmFudF90eXBlIjoidXJuOmlibTpwYXJhbXM6b2F1dGg6Z3JhbnQtdHlwZTphcGlrZXkiLCJzY29wZSI6ImlibSBvcGVuaWQiLCJjbGllbnRfaWQiOiJkZWZhdWx0IiwiYWNyIjoxLCJhbXIiOlsicHdkIl19.AKukj3OQQCFbowjlYesGiIl3GO_YUUqPjjiIJjiQIjHp0lIE1Shs5Pi-MhnYRjJMxCv0EASjvjbhneCAVatcGAW3vPpa_U8Ciad-LvBnERgH_LldT1gePY94r0nYiOKC4neaKInRXi5mpKE5mScWSBymagze46zecIco4eiUDzXtVdAVSd9H7Q3AJ5ZJs-fV6YxijsRtk6iikDyqrGwz_WrFcRk6W4G4lzHBRYWsZ9mdhdiDnww2cViI0xg6qXz6eIhtxas-FZoPRozll0Qm1rDh-o1hYd9zbiBe8Q05past2Syx9A47YZuT5D1G5pd5_epuktrnUF5uwsGrsyMmKg\"\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "\turl,\n",
    "\theaders=headers,\n",
    "\tjson=body\n",
    ")\n",
    "\n",
    "if response.status_code != 200:\n",
    "\traise Exception(\"Non-200 response: \" + str(response.text))\n",
    "\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h2 nama kelompok :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': 'google/flan-ul2',\n",
       " 'created_at': '2024-05-17T13:54:20.956Z',\n",
       " 'results': [{'generated_text': \"1. The VA needed to acquire my retirement points to verify my veteran status. 2. The underwriting department took a long time to verify my employment status. 3. The push back for my mortgage is common for mortgage companies, but this caused my interest rate to go up. 4. The securing of a closing lawyer being made aware to me and the lawyer needing three days to get their end prepared for me to go to their office to sign the paperwork wasn'''t made aware to me. 5. For whatever reason, the locked in interest rate jumped up 5/8 points.\",\n",
       "   'generated_token_count': 120,\n",
       "   'input_token_count': 1680,\n",
       "   'stop_reason': 'eos_token'}],\n",
       " 'system': {'warnings': [{'message': 'This model is a Non-IBM Product governed by a third-party license that may impose use restrictions and other obligations. By using this model you agree to its terms as identified in the following URL.',\n",
       "    'id': 'disclaimer_warning',\n",
       "    'more_info': 'https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx'}]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eyJraWQiOiIyMDI0MDUwNTA4MzkiLCJhbGciOiJSUzI1NiJ9.eyJpYW1faWQiOiJJQk1pZC02OTIwMDBDNjc2IiwiaWQiOiJJQk1pZC02OTIwMDBDNjc2IiwicmVhbG1pZCI6IklCTWlkIiwianRpIjoiZTllOGU3MjUtZjIxMC00ZDAxLTgwMTQtMDk3ZGNhY2FkNWI3IiwiaWRlbnRpZmllciI6IjY5MjAwMEM2NzYiLCJnaXZlbl9uYW1lIjoiQWxpIiwiZmFtaWx5X25hbWUiOiJNdXJ0YWRobyIsIm5hbWUiOiJBbGkgTXVydGFkaG8iLCJlbWFpbCI6ImlkLmFsaW11cnRhZGhvQGdtYWlsLmNvbSIsInN1YiI6ImlkLmFsaW11cnRhZGhvQGdtYWlsLmNvbSIsImF1dGhuIjp7InN1YiI6ImlkLmFsaW11cnRhZGhvQGdtYWlsLmNvbSIsImlhbV9pZCI6IklCTWlkLTY5MjAwMEM2NzYiLCJuYW1lIjoiQWxpIE11cnRhZGhvIiwiZ2l2ZW5fbmFtZSI6IkFsaSIsImZhbWlseV9uYW1lIjoiTXVydGFkaG8iLCJlbWFpbCI6ImlkLmFsaW11cnRhZGhvQGdtYWlsLmNvbSJ9LCJhY2NvdW50Ijp7InZhbGlkIjp0cnVlLCJic3MiOiIzOTlhMGRlNmEyNzE0ZTY3YTUwM2Y2N2Q0MzUwNmM1MSIsImltc191c2VyX2lkIjoiMTIwNTUzNzciLCJmcm96ZW4iOnRydWUsImlzX2VudGVycHJpc2VfYWNjb3VudCI6ZmFsc2UsImVudGVycHJpc2VfaWQiOiI5YTBjMjUwOWE0OTk0N2U0YTFkYjJhYzczZGI4MzI5MyIsImltcyI6IjI4MTEzNjkifSwiaWF0IjoxNzE1OTU0MTcwLCJleHAiOjE3MTU5NTc3NzAsImlzcyI6Imh0dHBzOi8vaWFtLmNsb3VkLmlibS5jb20vaWRlbnRpdHkiLCJncmFudF90eXBlIjoidXJuOmlibTpwYXJhbXM6b2F1dGg6Z3JhbnQtdHlwZTphcGlrZXkiLCJzY29wZSI6ImlibSBvcGVuaWQiLCJjbGllbnRfaWQiOiJkZWZhdWx0IiwiYWNyIjoxLCJhbXIiOlsicHdkIl19.Wv1dpZNS_v3UMNqMQunFv3dyZkdq1HN4a2n9dv9T_Sg1oMsRpMlrOWkyxhah9CvVJ70a-UjW6I9XH4TbrNoPAgaPIZSBY-8PIW0X2O2WjR3nv1LjX-drHUKSbDlTUoao9Y4hs8sZyjp9ak0ebSkYzhXzFVwrwKUtEJgTOxaL8axfS7jGQR1N0tcMBOKxqOuOm74VTtZVIX2C-YvGQmmw307I4KyJFetEqckQ3i-MmtLo_5QEMklX7dioNcsLl4424Sz-qQrr6y9bbvNolUI3thvlIAGvB29BVCN0JargyLQV8C1WexAmd998beLyYQ5vtfL_t9W76JyzhVTjlrO3Cw\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "author: Elena Lowery\n",
    "\n",
    "This code sample shows how to invoke Large Language Models (LLMs) deployed in watsonx.ai.\n",
    "Documentation: https://ibm.github.io/watson-machine-learning-sdk/foundation_models.html\n",
    "You will need to provide your IBM Cloud API key and a watonx.ai project id  (any project)\n",
    "for accessing watsonx.ai in a .env file\n",
    "This example shows simple use cases without comprehensive prompt tuning\n",
    "\"\"\"\n",
    "\n",
    "# Install the wml api your Python env prior to running this example:\n",
    "# pip install ibm-watson-machine-learning\n",
    "# pip install ibm-cloud-sdk-core\n",
    "\n",
    "# In non-Anaconda Python environments, you may also need to install dotenv\n",
    "# pip install python-dotenv\n",
    "\n",
    "# For reading credentials from the .env file\n",
    "import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# WML python SDK\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes, DecodingMethods\n",
    "\n",
    "# For invocation of LLM with REST API\n",
    "import requests, json\n",
    "from ibm_cloud_sdk_core import IAMTokenManager\n",
    "\n",
    "# Important: hardcoding the API key in Python code is not a best practice. We are using\n",
    "# this approach for the ease of demo setup. In a production application these variables\n",
    "# can be stored in an .env or a properties file\n",
    "\n",
    "# URL of the hosted LLMs is hardcoded because at this time all LLMs share the same endpoint\n",
    "url = \"url ibm cloud\"\n",
    "\n",
    "# These global variables will be updated in get_credentials() functions\n",
    "watsonx_project_id = \"your project \"\n",
    "# Replace with your IBM Cloud key\n",
    "api_key = \"generate api key https://vest.buildlab.cloud/en/watsonx/watsonxai/104\"\n",
    "\n",
    "def get_credentials():\n",
    "\n",
    "#     load_dotenv()\n",
    "\n",
    "    # Update the global variables that will be used for authentication in another function\n",
    "    globals()[\"api_key\"] = api_key\n",
    "    globals()[\"watsonx_project_id\"] = watsonx_project_id\n",
    "\n",
    "# The get_model function creates an LLM model object with the specified parameters\n",
    "def get_model(model_type,max_tokens,min_tokens,decoding,temperature):\n",
    "\n",
    "    generate_params = {\n",
    "        GenParams.MAX_NEW_TOKENS: max_tokens,\n",
    "        GenParams.MIN_NEW_TOKENS: min_tokens,\n",
    "        GenParams.DECODING_METHOD: decoding,\n",
    "        GenParams.TEMPERATURE: temperature\n",
    "    }\n",
    "\n",
    "    model = Model(\n",
    "        model_id=model_type,\n",
    "        params=generate_params,\n",
    "        credentials={\n",
    "            \"apikey\": api_key,\n",
    "            \"url\": url\n",
    "        },\n",
    "        project_id=watsonx_project_id\n",
    "        )\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_list_of_complaints():\n",
    "\n",
    "    # Look up parameters in documentation:\n",
    "    # https://ibm.github.io/watson-machine-learning-sdk/foundation_models.html#\n",
    "\n",
    "    # You can specify any prompt and change parameters for different runs\n",
    "\n",
    "    # If you want the end user to have a choice of the number of tokens in the output as well as decoding\n",
    "    # and temperature, you can parameterize these values\n",
    "\n",
    "    model_type = ModelTypes.LLAMA_2_13B_CHAT\n",
    "    max_tokens = 100\n",
    "    min_tokens = 50\n",
    "    decoding = DecodingMethods.GREEDY\n",
    "    # Temperature will be ignored if GREEDY is used\n",
    "    temperature = 0.7\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = get_model(model_type,max_tokens,min_tokens,decoding, temperature)\n",
    "\n",
    "    complaint = f\"\"\"\n",
    "            I just tried to book a flight on your incredibly slow website.  All \n",
    "            the times and prices were confusing.  I liked being able to compare \n",
    "            the amenities in economy with business class side by side.  But I \n",
    "            never got to reserve a seat because I didn't understand the seat map.  \n",
    "            Next time, I'll use a travel agent!\n",
    "            \"\"\"\n",
    "\n",
    "    # Hardcoding prompts in a script is not best practice. We are providing this code sample for simplicity of\n",
    "    # understanding\n",
    "\n",
    "    prompt_get_complaints = f\"\"\"\n",
    "    From the following customer complaint, extract 3 factors that caused the customer to be unhappy. \n",
    "    Put each factor on a new line. \n",
    "\n",
    "    Customer complaint:{complaint}\n",
    "\n",
    "    Numbered list of all the factors that caused the customer to be unhappy:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Invoke the model and print the results\n",
    "    generated_response = model.generate(prompt=prompt_get_complaints)\n",
    "    # WML API returns a dictionary object. Generated response is a list object that contains generated text\n",
    "    # as well as several other items such as token count and seed\n",
    "    # We recommmend that you put a breakpoint on this line and example the result object\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "    print(\"Prompt: \" + prompt_get_complaints)\n",
    "    print(\"List of complaints: \" + generated_response['results'][0]['generated_text'])\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "def answer_questions():\n",
    "\n",
    "    # Look up parameters in documentation:\n",
    "    # https://ibm.github.io/watson-machine-learning-sdk/foundation_models.html#\n",
    "\n",
    "    # You can specify any prompt and change parameters for different runs\n",
    "\n",
    "    # If you want the end user to have a choice of the number of tokens in the output as well as decoding\n",
    "    # and temperature, you can parameterize these values\n",
    "\n",
    "    final_prompt = \"Write a paragraph about the capital of France.\"\n",
    "    model_type = ModelTypes.FLAN_UL2\n",
    "    max_tokens = 300\n",
    "    min_tokens = 50\n",
    "    decoding = DecodingMethods.SAMPLE\n",
    "    temperature = 0.7\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = get_model(model_type,max_tokens,min_tokens,decoding, temperature)\n",
    "    # Invoke the model and print the results\n",
    "    generated_response = model.generate(prompt=final_prompt)\n",
    "    # WML API returns a dictionary object. Generated response is a list object that contains generated text\n",
    "    # as well as several other items such as token count and seed\n",
    "    # We recommmend that you put a breakpoint on this line and example the result object\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "    print(\"Question/request: \" + final_prompt)\n",
    "    print(\"Answer: \" + generated_response['results'][0]['generated_text'])\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "def invoke_with_REST():\n",
    "\n",
    "    rest_url =\"https://us-south.ml.cloud.ibm.com/ml/v1-beta/generation/text?version=2023-05-29\"\n",
    "\n",
    "    access_token = get_auth_token()\n",
    "\n",
    "    model_type = \"google/flan-ul2\"\n",
    "    max_tokens = 300\n",
    "    min_tokens = 50\n",
    "    decoding = \"sample\"\n",
    "    temperature = 0.7\n",
    "\n",
    "    final_prompt = \"Write a paragraph about the capital of France.\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + access_token\n",
    "        }\n",
    "\n",
    "    data = {\n",
    "        \"model_id\": model_type,\n",
    "        \"input\": final_prompt,\n",
    "        \"parameters\": {\n",
    "            \"decoding_method\": decoding,\n",
    "            \"max_new_tokens\": max_tokens,\n",
    "            \"min_new_tokens\": min_tokens,\n",
    "            \"temperature\": temperature,\n",
    "            \"stop_sequences\": [\".\"],\n",
    "            },\n",
    "        \"project_id\": watsonx_project_id\n",
    "    }\n",
    "\n",
    "    response = requests.post(rest_url, headers=headers, data=json.dumps(data))\n",
    "    generated_response = response.json()['results'][0]['generated_text']\n",
    "\n",
    "    print(\"--------------------------Invocation with REST-------------------------------------------\")\n",
    "    print(\"Question/request: \" + final_prompt)\n",
    "    print(\"Answer: \" + generated_response)\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "def get_auth_token():\n",
    "\n",
    "    # Access token is required for REST invocation of the LLM\n",
    "    access_token = IAMTokenManager(apikey=api_key,url=\"https://iam.cloud.ibm.com/identity/token\").get_token()\n",
    "    return access_token\n",
    "\n",
    "def demo_LLM_invocation():\n",
    "\n",
    "    # Load the api key and project id\n",
    "    get_credentials()\n",
    "\n",
    "    # Show examples of 2 use cases/prompts\n",
    "    answer_questions()\n",
    "    get_list_of_complaints()\n",
    "\n",
    "    # Simple prompt - invoked with the REST API\n",
    "    invoke_with_REST()\n",
    "\n",
    "# demo_LLM_invocation()\n",
    "print(get_auth_token())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Question/request: Write a paragraph about the capital of France.\n",
      "Answer: The capital city of France is Paris. The population of the city proper is 2,5 million and the population of the Paris metropolitan area is nearly 10 million. The area of the city and its suburbs is also called the Paris region, or the Paris Seine-et-Oise region.\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "Prompt: \n",
      "    From the following customer complaint, extract 3 factors that caused the customer to be unhappy. \n",
      "    Put each factor on a new line. \n",
      "\n",
      "    Customer complaint:\n",
      "            I just tried to book a flight on your incredibly slow website.  All \n",
      "            the times and prices were confusing.  I liked being able to compare \n",
      "            the amenities in economy with business class side by side.  But I \n",
      "            never got to reserve a seat because I didn't understand the seat map.  \n",
      "            Next time, I'll use a travel agent!\n",
      "            \n",
      "\n",
      "    Numbered list of all the factors that caused the customer to be unhappy:\n",
      "\n",
      "    \n",
      "List of complaints: 1. Slow website\n",
      "    2. Confusing times and prices\n",
      "    3. Lack of understanding of the seat map\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdemo_LLM_invocation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 210\u001b[0m, in \u001b[0;36mdemo_LLM_invocation\u001b[0;34m()\u001b[0m\n\u001b[1;32m    207\u001b[0m get_list_of_complaints()\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# Simple prompt - invoked with the REST API\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m \u001b[43minvoke_with_REST\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 187\u001b[0m, in \u001b[0;36minvoke_with_REST\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_type,\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: final_prompt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: watsonx_project_id\n\u001b[1;32m    184\u001b[0m }\n\u001b[1;32m    186\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(rest_url, headers\u001b[38;5;241m=\u001b[39mheaders, data\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(data))\n\u001b[0;32m--> 187\u001b[0m generated_response \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresults\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--------------------------Invocation with REST-------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion/request: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m final_prompt)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'results'"
     ]
    }
   ],
   "source": [
    "demo_LLM_invocation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 build model .H5\n",
    "2. eda - model evaluation (create and conclusion)\n",
    "3. testing predicting model \n",
    "4. deployment to ibm watson space \n",
    "5. generate api, acces with notebook by api"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
